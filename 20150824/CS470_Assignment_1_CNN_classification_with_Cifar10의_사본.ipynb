{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS470 Assignment #1: CNN classification with Cifar10의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqPMAzzNipD",
        "colab_type": "text"
      },
      "source": [
        "CS470 Assignment #1: CNN classification with Cifar10\n",
        "====\n",
        "\n",
        "Primary TA : Myeongjae Jang\n",
        "\n",
        "TA's E-mail : myeongjae0409@kaist.ac.kr\n",
        "\n",
        "## Instruction\n",
        "\n",
        "- Modify the baseline CNN model to improve the classification performance on Cifar10 dataset. In addition to the model definition, you can modify any parts of this colab example to improve the test accuracy (e.g., learning rate, batch size, etc.)\n",
        "- Train your CNN model and compare it to the baseline (in terms of training loss and the test accuracy).\n",
        "- Explain your modifications and discuss how you improved the test accuracy.\n",
        "\n",
        "## Submission guidelines\n",
        "\n",
        "- Your code and report will be all in Colab. Copy this example to your google drive and edit it to complete your assignment. Add sections at the bottom of this example to discuss the results. For discussion and analysis, we highly encourage you to use graphics if possible (e.g., plots, images, etc.). \n",
        "- To make grading efficient, please highlight all contributions & modifications you made clearly. We highly encourage you to add code blocks in the discussion section to discuss your modifications (e.g., you can describe the model definition in the discussion section using the code blocks).\n",
        "- We should be able to reproduce your results using your code and pre-trained model. Please double-check if your code runs without error and loads your pre-trained model properly. Submissions failed to run or reproduce the results will get a substantial penalty. \n",
        "- In this assignment, **we are not allowing fine-tuning from the pre-trained model** (e.g. ImageNet pre-trained models). You should train your  model on Cifar10 dataset from scratch. \n",
        "\n",
        "## Deliverables\n",
        "- Download your Colab notebook and the pre-trained model, and submit a zip file in a format: [StudentID].zip. Please double-check that you locate and load your pre-trained model properly.\n",
        "- Your assignment should be submitted through KLMS. All other submissions (e.g., via email) will not be considered as valid submissions. \n",
        "\n",
        "## Grading policy\n",
        "\n",
        "- **Code** (50%): Your code should work and outperform the baseline model in terms of the test accuracy. \n",
        "- **Report** (50%): Explain your modification and justify how it improved the perofrmance. It would be great if you have some supporting results for your justification (e.g., justifying that you resolved the overfitting by comparing two training/testing loss curves). \n",
        "- **Extra points** will be given if your submission satisfies the following:\n",
        " - **High test accuracy**: we will rank the submissions based on the test accuracy, and assign extra points according to the rank (e.g. 3 points for top 10%, 2 points for top 30%, 1 points for top 50%.)\n",
        " - **Comprehensive discussion**: we will assign extra points if your report contains comprehensive discussion/analysis of the results. Examples include justification of your choice of model (or hyper-parameters), comparisons to the baseline model (analysis on the source of improvement), insightful visualizations (loss curves, misclassification results), etc.\n",
        "\n",
        "## Due date\n",
        "- **23:59:59 September 25th.**\n",
        "- Late submission is allowed until 23:59:59 September 27th.\n",
        "- Late submission will be applied 20% penalty.\n",
        "\n",
        "## Questions\n",
        "- Please use QnA board in KLMS as a main communication channel. When you post questions, please make it public so that all students can share the information. Please use the prefix \"[Assignment 1]\" in the subject for all questions regarding this assignment (e.g., [Assignment 1] Regarding the grading policy).\n",
        "\n",
        "## PyTorch Documentation\n",
        "- You can refer PyTorch documentation for your assignment.\n",
        "- https://pytorch.org/docs/stable/index.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO1mgGV_uOIK",
        "colab_type": "text"
      },
      "source": [
        "## Step 1: Connect to your Google Drive\n",
        "\n",
        "It is required if you want to save checkpoints and load them later on.\n",
        "\n",
        "### (You have to submit your trained results as the checkpoint. So, please check your Google Drive connection again.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLth6ZfXuSGT",
        "colab_type": "code",
        "outputId": "295f44d1-ac8f-401c-a820-75e7d062af7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/gdrive')\n",
        "gdrive_root = '/gdrive/My Drive'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYwUwGf8qW1U",
        "colab_type": "text"
      },
      "source": [
        "## Step 2: Import modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UtshANjqpy4",
        "colab_type": "code",
        "outputId": "4a90d336-5b66-48e6-e681-1de4c772159e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "!pip install -U tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "\n",
        "torch.manual_seed(470)\n",
        "torch.cuda.manual_seed(470)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iJ-Q6sbq8c3",
        "colab_type": "text"
      },
      "source": [
        "## Step 3: Configure the experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA5jAy7Wq-E2",
        "colab_type": "code",
        "outputId": "4c081108-b699-436f-aacb-37aa80c2ba76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# training & optimization hyper-parameters\n",
        "max_epoch = 40\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "device = 'cuda'\n",
        "\n",
        "# model hyper-parameters\n",
        "output_dim = 10 \n",
        "\n",
        "# Boolean value to select training process\n",
        "training_process = True\n",
        "\n",
        "# initialize tensorboard for visualization\n",
        "# Note : click the Tensorboard link to see the visualization of training/testing results\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://1b1df546.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tZt60aMrQ1g",
        "colab_type": "text"
      },
      "source": [
        "## Step 4: Construct data pipeline\n",
        "\n",
        "**`torchvision.datasets.CIFAR10`** will automatically construct **`Cifar10`** dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHbtV46LrXOF",
        "colab_type": "code",
        "outputId": "68d2e6de-ef2e-4642-be8c-3ca4a0ea2d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "data_dir = os.path.join(gdrive_root, 'my_data')\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=True, transform=transform)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G_dWd-6rwWb",
        "colab_type": "text"
      },
      "source": [
        "## Step 5: Construct a neural network builder\n",
        "\n",
        "We serve the baseline CNN model which is supported on Pytorch tutorial: https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/cifar10_tutorial.ipynb#scrollTo=c1E1b7-igUcR\n",
        "\n",
        "### (You have to compare your own CNN model's test accuracy with the baseline CNN model and explain why your own model's test accuracy is higher than the basline.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX_wne0Vr1E5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(MyClassifier, self).__init__()\n",
        "      self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "      #layer1 \n",
        "      self.conv1_1 = nn.Conv2d(64, 64, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn1_1 = nn.BatchNorm2d(64)\n",
        "      self.conv1_2 = nn.Conv2d(64, 64, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn1_2 = nn.BatchNorm2d(64)\n",
        "\n",
        "      self.conv1_3 = nn.Conv2d(64, 64, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn1_3 = nn.BatchNorm2d(64)\n",
        "      self.conv1_4 = nn.Conv2d(64, 64, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn1_4 = nn.BatchNorm2d(64)\n",
        "\n",
        "      #layer2\n",
        "      self.conv2_1 = nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(2,2), padding=(1,1), bias=False)\n",
        "      self.bn2_1 = nn.BatchNorm2d(128)\n",
        "      self.conv2_2 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=(1,1), bias = False)\n",
        "      self.bn2_2 = nn.BatchNorm2d(128)\n",
        "      self.conv_bottle2_1 = nn.Conv2d(64, 128, kernel_size=(1,1), stride=(2,2), bias=False)\n",
        "      self.bn_bottle2_1 = nn.BatchNorm2d(128)\n",
        "\n",
        "      self.conv2_3 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn2_3 = nn.BatchNorm2d(128)\n",
        "      self.conv2_4 = nn.Conv2d(128, 128, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn2_4 = nn.BatchNorm2d(128)\n",
        "\n",
        "      #layer3\n",
        "      self.conv3_1 = nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(2,2), padding=(1,1), bias=False)\n",
        "      self.bn3_1 = nn.BatchNorm2d(256)\n",
        "      self.conv3_2 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1,1), bias = False)\n",
        "      self.bn3_2 = nn.BatchNorm2d(256)\n",
        "      self.conv_bottle3_1 = nn.Conv2d(128, 256, kernel_size=(1,1), stride=(2,2), bias=False)\n",
        "      self.bn_bottle3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "      self.conv3_3 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn3_3 = nn.BatchNorm2d(256)\n",
        "      self.conv3_4 = nn.Conv2d(256, 256, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn3_4 = nn.BatchNorm2d(256)\n",
        "      #layer4\n",
        "      self.conv4_1 = nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(2,2), padding=(1,1), bias=False)\n",
        "      self.bn4_1 = nn.BatchNorm2d(512)\n",
        "      self.conv4_2 = nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1,1), bias = False)\n",
        "      self.bn4_2 = nn.BatchNorm2d(512)\n",
        "      self.conv_bottle4_1 = nn.Conv2d(256, 512, kernel_size=(1,1), stride=(2,2), bias=False)\n",
        "      self.bn_bottle4_1 = nn.BatchNorm2d(512)\n",
        "\n",
        "      self.conv4_3 = nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn4_3 = nn.BatchNorm2d(512)\n",
        "      self.conv4_4 = nn.Conv2d(512, 512, kernel_size=(3, 3), padding=(1,1), bias=False)\n",
        "      self.bn4_4 = nn.BatchNorm2d(512)\n",
        "      self.dropout = nn.Dropout()\n",
        "\n",
        "\n",
        "      self.linear = nn.Linear(512, 10)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = F.relu(self.bn1(self.conv1(x)))\n",
        "\n",
        "      #layer1\n",
        "      bottle = x\n",
        "      x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "      x = self.bn1_2(self.conv1_2(x))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      bottle = x\n",
        "      x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
        "      x = self.bn1_4(self.conv1_4(x))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      #layer 2\n",
        "      bottle = x\n",
        "      x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "      x = self.bn2_2(self.conv2_2(x))\n",
        "      bottle = self.bn_bottle2_1 (self.conv_bottle2_1(bottle))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      bottle = x\n",
        "      x = F.relu (self.bn2_3(self.conv2_3(x)))\n",
        "      x = self.bn2_4(self.conv2_3(x))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      #layer 3\n",
        "      bottle = x\n",
        "      x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "      x = self.bn3_2(self.conv3_2(x))\n",
        "      bottle = self.bn_bottle3_1 (self.conv_bottle3_1(bottle))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      bottle = x\n",
        "      x = F.relu (self.bn3_3(self.conv3_3(x)))\n",
        "      x = self.bn3_4(self.conv3_3(x))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "      #layer 4\n",
        "      bottle = x\n",
        "      x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
        "      x = self.bn4_2(self.conv4_2(x))\n",
        "      bottle = self.bn_bottle4_1 (self.conv_bottle4_1(bottle))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      bottle = x\n",
        "      x = F.relu (self.bn4_3(self.conv4_3(x)))\n",
        "      x = self.bn4_4(self.conv4_3(x))\n",
        "      x += bottle \n",
        "      x = F.relu(x)\n",
        "\n",
        "      ##\n",
        "      x = F.avg_pool2d(x, 4)\n",
        "      # print(x.size())\n",
        "      x = x.view(x.size(0), -1)\n",
        "      # print(x.size())\n",
        "      x = self.dropout(x)\n",
        "      x = self.linear(x)\n",
        "      return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpA3xhjMspvA",
        "colab_type": "text"
      },
      "source": [
        "## Step 6: Initialize the network and optimizer\n",
        "\n",
        "If you want to train modularized neural network in Step 5B, please use 'MyClassifier2' as 'my_classifier'. It is written as a comment now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XP111gW0s8aH",
        "colab_type": "code",
        "outputId": "0554b75e-3b04-46bd-d2ac-cc8a65a4e9be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "my_classifier = MyClassifier()\n",
        "my_classifier = my_classifier.to(device)\n",
        "\n",
        "# apply xavier initializer\n",
        "def init_weights(m):\n",
        "  if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "    torch.nn.init.xavier_uniform(m.weight)\n",
        "\n",
        "my_classifier.apply(init_weights)\n",
        "\n",
        "# Print your neural network structure\n",
        "print(my_classifier)\n",
        "\n",
        "optimizer = optim.Adam(my_classifier.parameters(), lr=learning_rate)\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyClassifier(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1_3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv1_4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1_4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2_2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bottle2_1): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (bn_bottle2_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2_3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2_4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2_4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn3_2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bottle3_1): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (bn_bottle3_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn3_3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn3_4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn4_2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bottle4_1): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "  (bn_bottle4_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn4_3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn4_4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lAQeXmjsILS",
        "colab_type": "text"
      },
      "source": [
        "## Step 7: Load pre-trained weights if exist\n",
        "\n",
        "- **For your sumbmission you have to store the trained model as a checkpoint.**\n",
        "- Please do not erase this step.\n",
        "- If you want to modify this step, please be careful.\n",
        "- After training please confirm that your checkpoint is correctly stored and re-loaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFLNZxaBsHUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "04ab6b5d-4bcb-42ff-deba-a3b771e48569"
      },
      "source": [
        "ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  os.makedirs(ckpt_dir)\n",
        "  \n",
        "best_acc = 0.\n",
        "ckpt_path = os.path.join(ckpt_dir, 'ResNet.pt')\n",
        "if os.path.exists(ckpt_path):\n",
        "  ckpt = torch.load(ckpt_path)\n",
        "  try:\n",
        "    my_classifier.load_state_dict(ckpt['my_classifier'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer'])\n",
        "    best_acc = ckpt['best_acc']\n",
        "  except RuntimeError as e:\n",
        "      print('wrong checkpoint')\n",
        "  else:    \n",
        "    print('checkpoint is loaded !')\n",
        "    print('current best accuracy : %.2f' % best_acc)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint is loaded !\n",
            "current best accuracy : 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1t7n6yttNEc",
        "colab_type": "text"
      },
      "source": [
        "## Step 8: Train the network\n",
        "\n",
        "Note : It would be better to save checkpoints periodically, otherwise you'll lose everything you've trained if the session is recycled."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vczdKbytV38",
        "colab_type": "code",
        "outputId": "25ccbde9-80d9-42b7-dbc4-6abbecc94206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "training_process = True\n",
        "if training_process:\n",
        "  it = 0\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  for epoch in range(max_epoch):\n",
        "    # train phase\n",
        "    my_classifier.train()\n",
        "    for inputs, labels in train_dataloader:\n",
        "      it += 1\n",
        "\n",
        "      # load data to the GPU.\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # feed data into the network and get outputs.\n",
        "      logits = my_classifier(inputs)\n",
        "\n",
        "      # calculate loss\n",
        "      # Note: `F.cross_entropy` function receives logits, or pre-softmax outputs, rather than final probability scores.\n",
        "      loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "      # Note: You should flush out gradients computed at the previous step before computing gradients at the current step. \n",
        "      #       Otherwise, gradients will accumulate.\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # backprogate loss.\n",
        "      loss.backward()\n",
        "\n",
        "      # update the weights in the network.\n",
        "      optimizer.step()\n",
        "\n",
        "      # calculate accuracy.\n",
        "      acc = (logits.argmax(dim=1) == labels).float().mean()\n",
        "\n",
        "      if it % 2000 == 0:\n",
        "        tbc.save_value('Loss', 'train_loss', it, loss.item())\n",
        "        print('[epoch:{}, iteration:{}] train loss : {:.4f} train accuracy : {:.4f}'.format(epoch, it, loss.item(), acc.item()))\n",
        "\n",
        "    # save losses in a list so that we can visualize them later.\n",
        "    train_losses.append(loss)  \n",
        "\n",
        "    # test phase\n",
        "    n = 0.\n",
        "    test_loss = 0.\n",
        "    test_acc = 0.\n",
        "    my_classifier.eval()\n",
        "    for test_inputs, test_labels in test_dataloader:\n",
        "      test_inputs = test_inputs.to(device)\n",
        "      test_labels = test_labels.to(device)\n",
        "\n",
        "      logits = my_classifier(test_inputs)\n",
        "      test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item()\n",
        "      test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item()\n",
        "      n += test_inputs.size(0)\n",
        "\n",
        "    test_loss /= n\n",
        "    test_acc /= n\n",
        "    test_losses.append(test_loss)\n",
        "    tbc.save_value('Loss', 'test_loss', it, test_loss)\n",
        "    print('[epoch:{}, iteration:{}] test_loss : {:.4f} test accuracy : {:.4f}'.format(epoch, it, test_loss, test_acc)) \n",
        "\n",
        "    tbc.flush_line('train_loss')\n",
        "    tbc.flush_line('test_loss')\n",
        "\n",
        "    # save checkpoint whenever there is improvement in performance\n",
        "    if test_acc > best_acc:\n",
        "      best_acc = test_acc\n",
        "      # Note: optimizer also has states ! don't forget to save them as well.\n",
        "      ckpt = {'my_classifier':my_classifier.state_dict(),\n",
        "              'optimizer':optimizer.state_dict(),\n",
        "              'best_acc':best_acc}\n",
        "      torch.save(ckpt, ckpt_path)\n",
        "      print('checkpoint is saved !')\n",
        "    \n",
        "tbc.close()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch:0, iteration:1563] test_loss : 0.5753 test accuracy : 0.8371\n",
            "[epoch:1, iteration:2000] train loss : 0.0252 train accuracy : 1.0000\n",
            "[epoch:1, iteration:3126] test_loss : 0.5936 test accuracy : 0.8355\n",
            "[epoch:2, iteration:4000] train loss : 0.2059 train accuracy : 0.9062\n",
            "[epoch:2, iteration:4689] test_loss : 0.6574 test accuracy : 0.8363\n",
            "[epoch:3, iteration:6000] train loss : 0.0788 train accuracy : 0.9688\n",
            "[epoch:3, iteration:6252] test_loss : 0.6650 test accuracy : 0.8312\n",
            "[epoch:4, iteration:7815] test_loss : 0.6826 test accuracy : 0.8360\n",
            "[epoch:5, iteration:8000] train loss : 0.0625 train accuracy : 0.9688\n",
            "[epoch:5, iteration:9378] test_loss : 0.6680 test accuracy : 0.8415\n",
            "[epoch:6, iteration:10000] train loss : 0.1332 train accuracy : 0.9375\n",
            "[epoch:6, iteration:10941] test_loss : 0.7439 test accuracy : 0.8365\n",
            "[epoch:7, iteration:12000] train loss : 0.0025 train accuracy : 1.0000\n",
            "[epoch:7, iteration:12504] test_loss : 0.6957 test accuracy : 0.8440\n",
            "[epoch:8, iteration:14000] train loss : 0.0233 train accuracy : 1.0000\n",
            "[epoch:8, iteration:14067] test_loss : 0.7305 test accuracy : 0.8425\n",
            "[epoch:9, iteration:15630] test_loss : 0.7822 test accuracy : 0.8338\n",
            "[epoch:10, iteration:16000] train loss : 0.0051 train accuracy : 1.0000\n",
            "[epoch:10, iteration:17193] test_loss : 0.7690 test accuracy : 0.8380\n",
            "[epoch:11, iteration:18000] train loss : 0.0007 train accuracy : 1.0000\n",
            "[epoch:11, iteration:18756] test_loss : 0.7520 test accuracy : 0.8426\n",
            "[epoch:12, iteration:20000] train loss : 0.0104 train accuracy : 1.0000\n",
            "[epoch:12, iteration:20319] test_loss : 0.7717 test accuracy : 0.8430\n",
            "[epoch:13, iteration:21882] test_loss : 0.8142 test accuracy : 0.8413\n",
            "[epoch:14, iteration:22000] train loss : 0.0680 train accuracy : 0.9688\n",
            "[epoch:14, iteration:23445] test_loss : 0.7334 test accuracy : 0.8428\n",
            "[epoch:15, iteration:24000] train loss : 0.0615 train accuracy : 0.9688\n",
            "[epoch:15, iteration:25008] test_loss : 0.7383 test accuracy : 0.8456\n",
            "[epoch:16, iteration:26000] train loss : 0.0053 train accuracy : 1.0000\n",
            "[epoch:16, iteration:26571] test_loss : 0.7401 test accuracy : 0.8537\n",
            "checkpoint is saved !\n",
            "[epoch:17, iteration:28000] train loss : 0.0043 train accuracy : 1.0000\n",
            "[epoch:17, iteration:28134] test_loss : 0.7819 test accuracy : 0.8455\n",
            "[epoch:18, iteration:29697] test_loss : 0.8037 test accuracy : 0.8471\n",
            "[epoch:19, iteration:30000] train loss : 0.0005 train accuracy : 1.0000\n",
            "[epoch:19, iteration:31260] test_loss : 0.7939 test accuracy : 0.8489\n",
            "[epoch:20, iteration:32000] train loss : 0.0307 train accuracy : 1.0000\n",
            "[epoch:20, iteration:32823] test_loss : 0.8083 test accuracy : 0.8481\n",
            "[epoch:21, iteration:34000] train loss : 0.0023 train accuracy : 1.0000\n",
            "[epoch:21, iteration:34386] test_loss : 0.8580 test accuracy : 0.8414\n",
            "[epoch:22, iteration:35949] test_loss : 0.8534 test accuracy : 0.8480\n",
            "[epoch:23, iteration:36000] train loss : 0.0197 train accuracy : 1.0000\n",
            "[epoch:23, iteration:37512] test_loss : 0.8753 test accuracy : 0.8446\n",
            "[epoch:24, iteration:38000] train loss : 0.0610 train accuracy : 0.9688\n",
            "[epoch:24, iteration:39075] test_loss : 0.8649 test accuracy : 0.8445\n",
            "[epoch:25, iteration:40000] train loss : 0.0007 train accuracy : 1.0000\n",
            "[epoch:25, iteration:40638] test_loss : 0.9007 test accuracy : 0.8415\n",
            "[epoch:26, iteration:42000] train loss : 0.0183 train accuracy : 1.0000\n",
            "[epoch:26, iteration:42201] test_loss : 0.9007 test accuracy : 0.8473\n",
            "[epoch:27, iteration:43764] test_loss : 0.8664 test accuracy : 0.8477\n",
            "[epoch:28, iteration:44000] train loss : 0.0073 train accuracy : 1.0000\n",
            "[epoch:28, iteration:45327] test_loss : 0.8687 test accuracy : 0.8454\n",
            "[epoch:29, iteration:46000] train loss : 0.0381 train accuracy : 0.9688\n",
            "[epoch:29, iteration:46890] test_loss : 0.8703 test accuracy : 0.8449\n",
            "[epoch:30, iteration:48000] train loss : 0.0007 train accuracy : 1.0000\n",
            "[epoch:30, iteration:48453] test_loss : 0.7783 test accuracy : 0.8535\n",
            "[epoch:31, iteration:50000] train loss : 0.0037 train accuracy : 1.0000\n",
            "[epoch:31, iteration:50016] test_loss : 0.9051 test accuracy : 0.8464\n",
            "[epoch:32, iteration:51579] test_loss : 0.8554 test accuracy : 0.8481\n",
            "[epoch:33, iteration:52000] train loss : 0.0006 train accuracy : 1.0000\n",
            "[epoch:33, iteration:53142] test_loss : 0.8800 test accuracy : 0.8474\n",
            "[epoch:34, iteration:54000] train loss : 0.0026 train accuracy : 1.0000\n",
            "[epoch:34, iteration:54705] test_loss : 0.8996 test accuracy : 0.8423\n",
            "[epoch:35, iteration:56000] train loss : 0.0042 train accuracy : 1.0000\n",
            "[epoch:35, iteration:56268] test_loss : 0.9638 test accuracy : 0.8402\n",
            "[epoch:36, iteration:57831] test_loss : 0.9769 test accuracy : 0.8470\n",
            "[epoch:37, iteration:58000] train loss : 0.0140 train accuracy : 1.0000\n",
            "[epoch:37, iteration:59394] test_loss : 0.8724 test accuracy : 0.8492\n",
            "[epoch:38, iteration:60000] train loss : 0.0001 train accuracy : 1.0000\n",
            "[epoch:38, iteration:60957] test_loss : 0.8571 test accuracy : 0.8522\n",
            "[epoch:39, iteration:62000] train loss : 0.0154 train accuracy : 1.0000\n",
            "[epoch:39, iteration:62520] test_loss : 0.9061 test accuracy : 0.8461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECu3yS0OvfoR",
        "colab_type": "text"
      },
      "source": [
        "## Step 9: Visualize and analyze the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G89sqVp-vLRy",
        "colab_type": "code",
        "outputId": "76df9146-f0fe-488a-faab-9fb16dd0fa00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "\n",
        "training_process = False\n",
        "\n",
        "if not training_process:\n",
        "  # Re-load trained model\n",
        "  my_classifier.load_state_dict(ckpt['my_classifier'])\n",
        "  optimizer.load_state_dict(ckpt['optimizer'])\n",
        "\n",
        "  # Testing\n",
        "  n = 0.\n",
        "  test_loss = 0.\n",
        "  test_acc = 0.\n",
        "  my_classifier.eval()\n",
        "  for test_inputs, test_labels in test_dataloader:\n",
        "    test_inputs = test_inputs.to(device)\n",
        "    test_labels = test_labels.to(device)\n",
        "\n",
        "    logits = my_classifier(test_inputs)\n",
        "    test_loss += F.cross_entropy(logits, test_labels, reduction='sum').item()\n",
        "    test_acc += (logits.argmax(dim=1) == test_labels).float().sum().item()\n",
        "    n += test_inputs.size(0)\n",
        "\n",
        "  test_loss /= n\n",
        "  test_acc /= n\n",
        "  print('Test_loss : {:.4f}, Test accuracy : {:.4f}'.format(test_loss, test_acc))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n",
            "Test_loss : 0.9061, Test accuracy : 0.8461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkuQuhBAuSJK7EEK4IEnuQgjhgv4/jPIN2ruJE7cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHjD9SGrvhzc",
        "colab_type": "code",
        "outputId": "31dc532c-b77a-474d-c2fe-39ff9b71a00b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "my_classifier.eval()\n",
        "\n",
        "num_test_samples = len(test_dataset)\n",
        "random_idx = random.randint(0, num_test_samples)\n",
        "\n",
        "test_input, test_label = test_dataset.__getitem__(random_idx)\n",
        "test_prediction = F.softmax(my_classifier(test_input.unsqueeze(0).to(device)), dim=1).argmax().item()\n",
        "print('label : %s' % classes[test_label])\n",
        "print('prediction : %s' % classes[test_prediction])\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(test_input))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label : dog\n",
            "prediction : bird\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwcY8z_C2QLA",
        "colab_type": "text"
      },
      "source": [
        "# <font color=\"blue\"> Discussion and Analysis </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2W0ZtF82Xyb",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"blue\"> Fill here with your discussion </font>\n",
        "- Model Tuning\n",
        "1. dropout\n",
        "\n",
        "  I add dropout layer before multilinear layers.\n",
        "\n",
        "2. batch normalization in every cnn layer\n",
        "\n",
        "  I add batch normalization in every cnn layer to normalize input batch. \n",
        "3. Xavier initializer\n",
        "\n",
        "  I use Xavier initializer to initialize my initial model.\n",
        "4. Batch Size\n",
        "   \n",
        "   I change batch size from 4 to 32. Big batch size increase learning speed and proper batch size help escaping local minima or saddle situation when DNN is learning.\n",
        "5. number of epoches.\n",
        "  I change number of epoches from 20 to 40. In my experiment, 20 is too small to learn. I watched test accuracy increase after 20 epoches.\n",
        "  \n",
        "  This is my experience about model tuning. Base model is 2 conv layer and one multi perseptron.\n",
        "  ![experiment result](https://drive.google.com/open?id=1oaIS8YNQY0dszNX54wJ7T1oR4ZcdDeXY)\n",
        "\n",
        "- Model Architecture\n",
        " \n",
        "  I implemented simple version of ResNet which is discussed in class. \n",
        "  \n",
        "  One of the most important problem of deep neural network is gradient vanishing, which makes decrease effect from loss to parameters. Gradient vanishing become worsen if neural network is deeper. The reason why gradient vanishing come out simple calculation of backpropagation.\n",
        "\n",
        "  When DNN back propagate, the weights are changed amount of some value, which is determined by multiplication of derivative form of layers. Each multiplication, derivative of activation form is calculated. However, the calculated value decrease since pre-calculated values are usually less than 1. Therefore backside of DNN weights change little bit compared to frontside.\n",
        "  \n",
        "  My model, ResNet, solve this problem efficiently considering bottle. The model save previous value, bottle, before forward, and after some steps, add bottle and present state of step value. Hence, the model help avoiding gradient vanishing, connecting information between backside and frondside.\n",
        "  \n",
        "- Result\n",
        "\n",
        "  Test_loss : 0.9061, Test accuracy : 0.8461\n",
        "  This graph start from 8 epoches to 48 epoches.\n",
        "  ![model result](https://https://drive.google.com/open?id=19HMSv6mxYmcPxbMa6dGIYgLgUf6_rGzv)"
      ]
    }
  ]
}